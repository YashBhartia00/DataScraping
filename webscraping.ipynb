{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webscraping.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nLlVhlFy6zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoTUyOs6ZnS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84JPY4OsetAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def clean(link):\n",
        "  try:\n",
        "    url= link\n",
        "    page = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "    contentp=soup.find_all(\"div\",class_=\"entry unvoted\" )\n",
        "    childnum=0\n",
        "    for p in contentp:\n",
        "      text=p.text\n",
        "      if 'children' in text:\n",
        "        child= text.index('child')\n",
        "        childnum=text[child-2:child-1]\n",
        "        extra=text[0:child+9]  \n",
        "        text=text.replace(extra,'')\n",
        "      elif 'child' in text:\n",
        "        childy=text.index('child')\n",
        "        childnum=text[childy-2:childy-1]\n",
        "        extra=text[0:childy+6]\n",
        "        text=text.replace(extra,'')\n",
        "      else: \n",
        "        titlei=text.index(\"(self.mentalhealth)\")\n",
        "        text=text.replace('(self.mentalhealth)','')\n",
        "        title=text[0:titlei]\n",
        "        text=text.replace(title, \"\")\n",
        "        extra=text[0:28]\n",
        "        extra2=text[titlei:11]\n",
        "        text=text.replace(extra,\"\")\n",
        "        text=text.replace(extra2,\"\")\n",
        "        postcont=text\n",
        "        \n",
        "      text=text.replace('permalinkembedsaveparentreportgive awardreply','')\n",
        "      text=text.replace('permalinkembedsavereportgive awardreply', '')\n",
        "      text=text.replace('announcementcommentsharesavehidereport','')\n",
        "      text=text.replace('(self.mentalhealth)','')\n",
        "      text=text.replace('commentssharesavehidereport','')\n",
        "      text=text.replace('commentsharesavehidereport','')\n",
        "\n",
        "      print(childnum,text)\n",
        "      writef(text)\n",
        "  except:\n",
        "      print(\"ErrorHere3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C4C9t_5zd5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sLb0XaFyT7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def writef(towrite):\n",
        "  files=open('data.txt','a+')\n",
        "  files.write(towrite)\n",
        "  files.write('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVjUNSLceaT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://old.reddit.com/r/mentalhealth/\"\n",
        "# Headers to mimic a browser visit\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "# Returns a requests.models.Response object\n",
        "for beta in range(40):\n",
        "  try:\n",
        "    page = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "    posts=soup.find_all(\"p\", class_=\"title\")\n",
        "    for p in posts:\n",
        "      propertext=p.text\n",
        "      propertext=propertext.replace('(self.mentalhealth)', '')\n",
        "      print(propertext)\n",
        "      h = p.findChildren()\n",
        "      link=\"https://old.reddit.com\" + h[0].get(\"href\")\n",
        "      clean(link)\n",
        "    try:\n",
        "      url=soup.find('a',rel='nofollow next').get('href')\n",
        "    except:\n",
        "      print('ErrorHere2')\n",
        "  except:\n",
        "    print('ErrorHere')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyDZqdhyzgdn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}